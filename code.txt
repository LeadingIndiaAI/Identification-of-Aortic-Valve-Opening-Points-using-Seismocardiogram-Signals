########imports############
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import datasets, linear_model
from mpl_toolkits.mplot3d import axes3d
import seaborn as sns
from sklearn.preprocessing import scale
import sklearn.linear_model as skl_lm
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.graphics.mosaicplot import mosaic
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale
print("Packages LOADED")
import os
os.chdir('C:\\Users\\Dell Notebook\\Desktop\\internship\\testing')
dataset_train = pd.read_csv('m002.csv')
dataset_trainp2 = pd.read_csv('m004.csv')
dataset_trainp3 = pd.read_csv('m001.csv')
dataset_trainp4 = pd.read_csv('m005.csv')
dataset_trainp5 = pd.read_csv('m006.csv')
dataset_trainp6 = pd.read_csv('m007.csv')
dataset_trainp7 = pd.read_csv('m008.csv')
dataset_trainp8 = pd.read_csv('m009.csv')
dataset_trainp9 = pd.read_csv('m010.csv')

###################taking scg column##############
training_set1 = dataset_train.iloc[:, 1:2].values
training_set2 = dataset_trainp2.iloc[:, 1:2].values
training_set3 = dataset_trainp3.iloc[:, 1:2].values
training_set4 = dataset_trainp4.iloc[:, 1:2].values
training_set5 = dataset_trainp5.iloc[:, 1:2].values
training_set6 = dataset_trainp6.iloc[:, 1:2].values
training_set7 = dataset_trainp7.iloc[:, 1:2].values
training_set8 = dataset_trainp8.iloc[:, 1:2].values
training_set9 = dataset_trainp9.iloc[:, 1:2].values

############scaling individual sets################
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t1 = sc.fit_transform(training_set1)
t1

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t2 = sc.fit_transform(training_set2)
t2

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t3 = sc.fit_transform(training_set3)
t3

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t4 = sc.fit_transform(training_set4)
t4

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t5 = sc.fit_transform(training_set5)
t5

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t6 = sc.fit_transform(training_set6)
t6

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t7 = sc.fit_transform(training_set7)
t7

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t8 = sc.fit_transform(training_set8)
t8

from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))
t9 = sc.fit_transform(training_set9)
t9
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

###### taking SCG values##################
y1 = dataset_train.iloc[:, 2:3].values
y2 = dataset_trainp2.iloc[:, 2:3].values
y3 = dataset_trainp3.iloc[:, 2:3].values
y4 = dataset_trainp4.iloc[:, 2:3].values
y5 = dataset_trainp5.iloc[:, 2:3].values
y6 = dataset_trainp6.iloc[:, 2:3].values
y7 = dataset_trainp7.iloc[:, 2:3].values
y8 = dataset_trainp8.iloc[:, 2:3].values
y9 = dataset_trainp9.iloc[:, 2:3].values

X=np.concatenate((t1,t2,t3,t4,t5,t6,t7,t8,t9),axis=0)

y=np.concatenate((y1,y2,y3,y4,y5,y6,y7,y8,y9),axis=0)

#########RANDOM FOREST#############

import matplotlib.pyplot as plt
import seaborn as sns
import re
from IPython.display import Image
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.externals.six import StringIO
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingRegressor,RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error
from sklearn import tree
from sklearn.metrics import accuracy_score
#from sklearn.cross_validation import KFold
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from IPython.display import Image as PImage
from subprocess import check_call
from PIL import Image, ImageDraw, ImageFont
pd.set_option('display.notebook_repr_html', False)
#get_ipython().magic('matplotlib inline')
plt.style.use('seaborn-white')
print("Package Loaded")


test_size = 0.33
from sklearn.model_selection import train_test_split
#pip install -U scikit-learn
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)
print('Partitioning Done!')
X_test.shape

y_train=y_train.ravel()

from sklearn import metrics

model = RandomForestClassifier(max_depth=5,n_estimators=500,oob_score=True)#DecisionTreeClassifier()

model.fit(X_train,y_train)

prediction = model.predict(X_test)
prediction

expected = y_test
predicted = prediction
conf = metrics.confusion_matrix(expected, predicted)
print(conf)
label = ["0","1"]
sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label)

outcome = y_test
print(metrics.accuracy_score(outcome,prediction))

##### LOGISTIC REGRESSION######
from sklearn.linear_model import LogisticRegression
logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)
predictions = logmodel.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,predictions))


#########SVM#############
from sklearn.svm import SVC
model = SVC()

model.fit(X_train,y_train)

# ## Predictions and Evaluations
predictions = model.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,predictions))

param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}

from sklearn.model_selection import GridSearchCV
grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)
grid.fit(X_train,y_train)

grid.best_params_

grid.best_estimator_

grid_predictions = grid.predict(X_test)

print(confusion_matrix(y_test,grid_predictions))






